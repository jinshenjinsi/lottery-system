#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çœŸå®å½©ç¥¨æ•°æ®æœåŠ¡å™¨
ä»å®˜æ–¹æ•°æ®æºè·å–çœŸå®çš„ç¦å½©3Då’ŒåŒè‰²çƒå¼€å¥–æ•°æ®
"""

from flask import Flask, jsonify, request, make_response
from flask_cors import CORS
import requests
from bs4 import BeautifulSoup
import json
import re
from datetime import datetime, timedelta
import time
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
# å…è®¸ /api/* è·¨åŸŸï¼Œç¡®ä¿åœ¨é”™è¯¯å“åº”ä¹Ÿè¿”å› CORS å¤´
CORS(app, resources={r"/api/*": {"origins": "*"}})

@app.after_request
def add_cors_headers(resp):
    try:
        resp.headers['Access-Control-Allow-Origin'] = '*'
        resp.headers['Access-Control-Allow-Methods'] = 'GET,POST,OPTIONS'
        resp.headers['Access-Control-Allow-Headers'] = 'Content-Type, Authorization'
    except Exception:
        pass
    return resp

@app.route('/api/<path:subpath>', methods=['OPTIONS'])
def api_cors_preflight(subpath):
    resp = make_response('', 200)
    resp.headers['Access-Control-Allow-Origin'] = '*'
    resp.headers['Access-Control-Allow-Methods'] = 'GET,POST,OPTIONS'
    resp.headers['Access-Control-Allow-Headers'] = 'Content-Type, Authorization'
    return resp

class RealLotteryDataScraper:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        })
        
        # é‡è¯•é…ç½®
        self.max_retries = 3
        self.retry_delay = 2  # ç§’
        
        # é…ç½®è¯·æ±‚è¶…æ—¶
        self.timeout = (5, 15)  # (è¿æ¥è¶…æ—¶, è¯»å–è¶…æ—¶)
    
    def get_fc3d_data(self, limit=300):
        """è·å–ç¦å½©3Då†å²æ•°æ®"""
        try:
            # ä»ä¸­å›½ç¦å½©ç½‘è·å–æ•°æ®
            data = self._scrape_fc3d_from_cwl()
            if data and len(data) > 0:
                logger.info(f"æˆåŠŸä»ä¸­å›½ç¦å½©ç½‘è·å–ç¦å½©3Dæ•°æ®ï¼Œå…±{len(data)}æœŸ")
                return data[:limit]
            
            # ä»ä¸­å½©ç½‘è·å–æ•°æ®
            data = self._scrape_fc3d_from_zhcw()
            if data and len(data) > 0:
                logger.info(f"æˆåŠŸä»ä¸­å½©ç½‘è·å–ç¦å½©3Dæ•°æ®ï¼Œå…±{len(data)}æœŸ")
                return data[:limit]
            
            logger.error("æ— æ³•è·å–ç¦å½©3Dæ•°æ®")
            return []
            
        except Exception as e:
            logger.error(f"è·å–ç¦å½©3Dæ•°æ®å¤±è´¥: {e}")
            return []
    
    def get_ssq_data(self, limit=300):
        """è·å–åŒè‰²çƒå†å²æ•°æ®"""
        try:
            # ä»ä¸­å›½ç¦å½©ç½‘è·å–æ•°æ®
            data = self._scrape_ssq_from_cwl()
            if data and len(data) > 0:
                logger.info(f"æˆåŠŸä»ä¸­å›½ç¦å½©ç½‘è·å–åŒè‰²çƒæ•°æ®ï¼Œå…±{len(data)}æœŸ")
                return data[:limit]
            
            # ä»ä¸­å½©ç½‘è·å–æ•°æ®
            data = self._scrape_ssq_from_zhcw()
            if data and len(data) > 0:
                logger.info(f"æˆåŠŸä»ä¸­å½©ç½‘è·å–åŒè‰²çƒæ•°æ®ï¼Œå…±{len(data)}æœŸ")
                return data[:limit]
            
            logger.error("æ— æ³•è·å–åŒè‰²çƒæ•°æ®")
            return []
            
        except Exception as e:
            logger.error(f"åŒè‰²çƒ APIé”™è¯¯: {e}")
            return []
    
    def _scrape_fc3d_from_cwl(self):
        """ä»ä¸­å›½ç¦å½©ç½‘è·å–ç¦å½©3Dæ•°æ®"""
        try:
            url = "https://www.cwl.gov.cn/cwl_admin/front/cwlkj/search/kjxx/findDrawNotice"
            params = {
                'name': '3d',
                'issueCount': '300',
                'issueStart': '',
                'issueEnd': '',
                'dayStart': '',
                'dayEnd': ''
            }
            
            headers = {
                'Accept': 'application/json, text/javascript, */*; q=0.01',
                'Referer': 'https://www.cwl.gov.cn/',
                'Origin': 'https://www.cwl.gov.cn',
                'X-Requested-With': 'XMLHttpRequest'
            }
            
            for retry in range(self.max_retries):
                try:
                    response = self.session.get(url, params=params, headers=headers, timeout=self.timeout)
                    if response.status_code == 200:
                        data = self._parse_fc3d_from_cwl_api(response)
                        if data and len(data) > 0:
                            return data
                except requests.Timeout:
                    logger.warning(f"ä¸­å›½ç¦å½©ç½‘è¯·æ±‚è¶…æ—¶ï¼Œç¬¬ {retry + 1} æ¬¡é‡è¯•")
                    if retry < self.max_retries - 1:
                        time.sleep(self.retry_delay)
                except Exception as e:
                    logger.error(f"è¯·æ±‚ä¸­å›½ç¦å½©ç½‘å¤±è´¥: {e}")
                    if retry < self.max_retries - 1:
                        time.sleep(self.retry_delay)
            
            return []
            
        except Exception as e:
            logger.error(f"ä»ä¸­å›½ç¦å½©ç½‘è·å–ç¦å½©3Dæ•°æ®å¤±è´¥: {e}")
            return []
    
    def _scrape_fc3d_from_zhcw(self):
        """ä»ä¸­å½©ç½‘è·å–ç¦å½©3Dæ•°æ®"""
        try:
            urls = [
                "https://www.zhcw.com/kjxx/3d/",
                "https://www.zhcw.com/kj/3d/"
            ]
            
            for url in urls:
                try:
                    response = self.session.get(url, timeout=self.timeout)
                    if response.status_code == 200:
                        data = self._parse_fc3d_from_zhcw_html(response)
                        if data and len(data) > 0:
                            return data
                except Exception as e:
                    logger.warning(f"ä¸­å½©ç½‘URL {url} å¤±è´¥: {e}")
            
            return []
            
        except Exception as e:
            logger.error(f"ä»ä¸­å½©ç½‘è·å–ç¦å½©3Dæ•°æ®å¤±è´¥: {e}")
            return []
    
    def _scrape_ssq_from_cwl(self):
        """ä»ä¸­å›½ç¦å½©ç½‘è·å–åŒè‰²çƒæ•°æ®"""
        try:
            url = "https://www.cwl.gov.cn/cwl_admin/front/cwlkj/search/kjxx/findDrawNotice"
            params = {
                'name': 'ssq',
                'issueCount': '300',
                'issueStart': '',
                'issueEnd': '',
                'dayStart': '',
                'dayEnd': ''
            }
            
            headers = {
                'Accept': 'application/json, text/javascript, */*; q=0.01',
                'Referer': 'https://www.cwl.gov.cn/',
                'Origin': 'https://www.cwl.gov.cn',
                'X-Requested-With': 'XMLHttpRequest'
            }
            
            for retry in range(self.max_retries):
                try:
                    response = self.session.get(url, params=params, headers=headers, timeout=self.timeout)
                    if response.status_code == 200:
                        data = self._parse_ssq_from_cwl_api(response)
                        if data and len(data) > 0:
                            return data
                except requests.Timeout:
                    logger.warning(f"ä¸­å›½ç¦å½©ç½‘è¯·æ±‚è¶…æ—¶ï¼Œç¬¬ {retry + 1} æ¬¡é‡è¯•")
                    if retry < self.max_retries - 1:
                        time.sleep(self.retry_delay)
                except Exception as e:
                    logger.error(f"è¯·æ±‚ä¸­å›½ç¦å½©ç½‘å¤±è´¥: {e}")
                    if retry < self.max_retries - 1:
                        time.sleep(self.retry_delay)
            
            return []
            
        except Exception as e:
            logger.error(f"ä»ä¸­å›½ç¦å½©ç½‘è·å–åŒè‰²çƒæ•°æ®å¤±è´¥: {e}")
            return []
    
    def _scrape_ssq_from_zhcw(self):
        """ä»ä¸­å½©ç½‘è·å–åŒè‰²çƒæ•°æ®"""
        try:
            urls = [
                "https://www.zhcw.com/kjxx/ssq/",
                "https://www.zhcw.com/kj/ssq/"
            ]
            
            for url in urls:
                try:
                    response = self.session.get(url, timeout=self.timeout)
                    if response.status_code == 200:
                        data = self._parse_ssq_from_zhcw_html(response)
                        if data and len(data) > 0:
                            return data
                except Exception as e:
                    logger.warning(f"ä¸­å½©ç½‘URL {url} å¤±è´¥: {e}")
            
            return []
            
        except Exception as e:
            logger.error(f"ä»ä¸­å½©ç½‘è·å–åŒè‰²çƒæ•°æ®å¤±è´¥: {e}")
            return []
    
    def _parse_fc3d_from_cwl_api(self, response):
        """ä»ä¸­å›½ç¦å½©ç½‘APIè§£æç¦å½©3Dæ•°æ®"""
        try:
            result = response.json()
            if result.get('state') == 0 and result.get('result'):
                data = []
                for item in result['result']:
                    try:
                        # è§£æå¼€å¥–å·ç 
                        number = item.get('red', '').replace(' ', '')
                        if not number or len(number) != 3:
                            continue
                            
                        # è§£ææ—¥æœŸå’ŒæœŸå·
                        date = item.get('date', '').split(' ')[0]
                        period = item.get('code', '')
                        if not date or not period:
                            continue
                            
                        # è®¡ç®—ç»Ÿè®¡æ•°æ®
                        digits = [int(d) for d in number]
                        data.append({
                            'period': period,
                            'date': date,
                            'number': number,
                            'sum': sum(digits),
                            'span': max(digits) - min(digits),
                            'oddCount': len([d for d in digits if d % 2 == 1]),
                            'evenCount': len([d for d in digits if d % 2 == 0]),
                            'bigCount': len([d for d in digits if d >= 5]),
                            'smallCount': len([d for d in digits if d < 5])
                        })
                    except Exception as e:
                        logger.debug(f"è§£æå•æ¡ç¦å½©3Dæ•°æ®å¤±è´¥: {e}")
                        continue
                        
                return data
            return []
        except Exception as e:
            logger.error(f"è§£æç¦å½©3Dæ•°æ®å¤±è´¥: {e}")
            return []
    
    def _parse_fc3d_from_zhcw_html(self, response):
        """ä»ä¸­å½©ç½‘HTMLè§£æç¦å½©3Dæ•°æ®"""
        try:
            data = []
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # å°è¯•å¤šç§è¡¨æ ¼é€‰æ‹©å™¨
            selectors = [
                'table.history-table',
                'table.kj-table',
                'table.lott-table',
                'table[class*="table"]',
                'table'
            ]
            
            for selector in selectors:
                table = soup.select_one(selector)
                if table:
                    rows = table.find_all('tr')[1:]  # è·³è¿‡è¡¨å¤´
                    for row in rows:
                        try:
                            cells = row.find_all(['td', 'th'])
                            if len(cells) < 3:
                                continue
                            
                            # æå–æœŸå·
                            period_text = cells[0].get_text(strip=True)
                            period_match = re.search(r'\d{7}', period_text)
                            if not period_match:
                                continue
                            period = period_match.group()
                            
                            # æå–æ—¥æœŸ
                            date_text = cells[1].get_text(strip=True)
                            date_match = re.search(r'\d{4}-\d{2}-\d{2}', date_text)
                            if not date_match:
                                continue
                            date = date_match.group()
                            
                            # æå–å·ç 
                            number_text = cells[2].get_text(strip=True)
                            number_match = re.search(r'\d{3}', number_text)
                            if not number_match:
                                continue
                            number = number_match.group()
                            
                            # è®¡ç®—ç»Ÿè®¡æ•°æ®
                            digits = [int(d) for d in number]
                            data.append({
                                'period': period,
                                'date': date,
                                'number': number,
                                'sum': sum(digits),
                                'span': max(digits) - min(digits),
                                'oddCount': len([d for d in digits if d % 2 == 1]),
                                'evenCount': len([d for d in digits if d % 2 == 0]),
                                'bigCount': len([d for d in digits if d >= 5]),
                                'smallCount': len([d for d in digits if d < 5])
                            })
                        except Exception as e:
                            logger.debug(f"è§£æå•æ¡ç¦å½©3Dæ•°æ®å¤±è´¥: {e}")
                            continue
                    
                    if data:
                        break
            
            return data
        except Exception as e:
            logger.error(f"è§£æç¦å½©3D HTMLæ•°æ®å¤±è´¥: {e}")
            return []
    
    def _parse_ssq_from_cwl_api(self, response):
        """ä»ä¸­å›½ç¦å½©ç½‘APIè§£æåŒè‰²çƒæ•°æ®"""
        try:
            result = response.json()
            if result.get('state') == 0 and result.get('result'):
                data = []
                for item in result['result']:
                    try:
                        # è§£æçº¢çƒ
                        red = item.get('red', '').replace(' ', '')
                        if not red:
                            continue
                        redBalls = [int(x) for x in red.split(',')]
                        if len(redBalls) != 6:
                            continue
                            
                        # è§£æè“çƒ
                        blueBall = int(item.get('blue', '0'))
                        if not blueBall:
                            continue
                            
                        # è§£ææ—¥æœŸå’ŒæœŸå·
                        date = item.get('date', '').split(' ')[0]
                        period = item.get('code', '')
                        if not date or not period:
                            continue
                            
                        data.append({
                            'period': period,
                            'date': date,
                            'redBalls': redBalls,
                            'blueBall': blueBall,
                            'redSum': sum(redBalls),
                            'redOddCount': len([n for n in redBalls if n % 2 == 1]),
                            'redEvenCount': len([n for n in redBalls if n % 2 == 0]),
                            'redBigCount': len([n for n in redBalls if n > 16]),
                            'redSmallCount': len([n for n in redBalls if n <= 16])
                        })
                    except Exception as e:
                        logger.debug(f"è§£æå•æ¡åŒè‰²çƒæ•°æ®å¤±è´¥: {e}")
                        continue
                        
                return data
            return []
        except Exception as e:
            logger.error(f"è§£æåŒè‰²çƒæ•°æ®å¤±è´¥: {e}")
            return []
    
    def _parse_ssq_from_zhcw_html(self, response):
        """ä»ä¸­å½©ç½‘HTMLè§£æåŒè‰²çƒæ•°æ®"""
        try:
            data = []
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # å°è¯•å¤šç§è¡¨æ ¼é€‰æ‹©å™¨
            selectors = [
                'table.history-table',
                'table.kj-table',
                'table.lott-table',
                'table[class*="table"]',
                'table'
            ]
            
            for selector in selectors:
                table = soup.select_one(selector)
                if table:
                    rows = table.find_all('tr')[1:]  # è·³è¿‡è¡¨å¤´
                    for row in rows:
                        try:
                            cells = row.find_all(['td', 'th'])
                            if len(cells) < 4:
                                continue
                            
                            # æå–æœŸå·
                            period_text = cells[0].get_text(strip=True)
                            period_match = re.search(r'\d{7}', period_text)
                            if not period_match:
                                continue
                            period = period_match.group()
                            
                            # æå–æ—¥æœŸ
                            date_text = cells[1].get_text(strip=True)
                            date_match = re.search(r'\d{4}-\d{2}-\d{2}', date_text)
                            if not date_match:
                                continue
                            date = date_match.group()
                            
                            # æå–çº¢çƒ
                            red_text = cells[2].get_text(strip=True)
                            red_numbers = re.findall(r'\d{2}', red_text)
                            if len(red_numbers) != 6:
                                continue
                            redBalls = [int(x) for x in red_numbers]
                            
                            # æå–è“çƒ
                            blue_text = cells[3].get_text(strip=True)
                            blue_match = re.search(r'\d{2}', blue_text)
                            if not blue_match:
                                continue
                            blueBall = int(blue_match.group())
                            
                            data.append({
                                'period': period,
                                'date': date,
                                'redBalls': redBalls,
                                'blueBall': blueBall,
                                'redSum': sum(redBalls),
                                'redOddCount': len([n for n in redBalls if n % 2 == 1]),
                                'redEvenCount': len([n for n in redBalls if n % 2 == 0]),
                                'redBigCount': len([n for n in redBalls if n > 16]),
                                'redSmallCount': len([n for n in redBalls if n <= 16])
                            })
                        except Exception as e:
                            logger.debug(f"è§£æå•æ¡åŒè‰²çƒæ•°æ®å¤±è´¥: {e}")
                            continue
                    
                    if data:
                        break
            
            return data
        except Exception as e:
            logger.error(f"è§£æåŒè‰²çƒHTMLæ•°æ®å¤±è´¥: {e}")
            return []

# åˆ›å»ºçˆ¬è™«å®ä¾‹
scraper = RealLotteryDataScraper()

@app.route('/api/fc3d', methods=['GET'])
def get_fc3d():
    """è·å–ç¦å½©3Dæ•°æ®API"""
    try:
        limit = request.args.get('limit', 300, type=int)
        data = scraper.get_fc3d_data(limit)
        
        if data:
            return jsonify({
                'success': True,
                'data': data,
                'count': len(data),
                'source': 'çœŸå®å¼€å¥–æ•°æ®'
            })
        else:
            return jsonify({
                'success': False,
                'message': 'æ— æ³•è·å–ç¦å½©3Dæ•°æ®',
                'data': []
            }), 500
            
    except Exception as e:
        logger.error(f"ç¦å½©3D APIé”™è¯¯: {e}")
        return jsonify({
            'success': False,
            'message': str(e),
            'data': []
        }), 500

@app.route('/api/ssq', methods=['GET'])
def get_ssq():
    """è·å–åŒè‰²çƒæ•°æ®API"""
    try:
        limit = request.args.get('limit', 300, type=int)
        data = scraper.get_ssq_data(limit)
        
        if data:
            return jsonify({
                'success': True,
                'data': data,
                'count': len(data),
                'source': 'çœŸå®å¼€å¥–æ•°æ®'
            })
        else:
            return jsonify({
                'success': False,
                'message': 'æ— æ³•è·å–åŒè‰²çƒæ•°æ®',
                'data': []
            }), 500
            
    except Exception as e:
        logger.error(f"åŒè‰²çƒ APIé”™è¯¯: {e}")
        return jsonify({
            'success': False,
            'message': str(e),
            'data': []
        }), 500

@app.route('/api/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥API"""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'message': 'çœŸå®å½©ç¥¨æ•°æ®æœåŠ¡å™¨è¿è¡Œæ­£å¸¸'
    })

if __name__ == '__main__':
    import os
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--port', type=int, default=int(os.environ.get('PORT', 5000)))
    args = parser.parse_args()
    port = args.port

    print("ğŸš€ å¯åŠ¨çœŸå®å½©ç¥¨æ•°æ®æœåŠ¡å™¨...")
    print("ğŸ“Š æ”¯æŒä»å¤šä¸ªå®˜æ–¹æ•°æ®æºè·å–çœŸå®å¼€å¥–æ•°æ®")
    print("ğŸŒ APIåœ°å€:")
    print(f"   - ç¦å½©3D: http://localhost:{port}/api/fc3d")
    print(f"   - åŒè‰²çƒ: http://localhost:{port}/api/ssq")
    print(f"   - å¥åº·æ£€æŸ¥: http://localhost:{port}/api/health")
    print(f"   - æ¸…é™¤ç¼“å­˜: http://localhost:{port}/api/clear_cache")
    
    app.run(host='0.0.0.0', port=port, debug=True)