#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¦å½©3D AIé¢„æµ‹æ¨¡å‹æ¼”ç¤º
æ³¨æ„ï¼šæ­¤æ¨¡å‹ä»…ç”¨äºå­¦ä¹ å’Œç ”ç©¶ï¼Œä¸ä¿è¯é¢„æµ‹å‡†ç¡®æ€§
"""

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')

class LotteryAIPredictor:
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.feature_names = [
            'period', 'day_of_week', 'month', 'hundreds', 'tens', 'ones',
            'sum_value', 'span_value', 'odd_count', 'even_count',
            'big_count', 'small_count', 'consecutive_count'
        ]
    
    def generate_training_data(self, num_periods=1000):
        """ç”Ÿæˆè®­ç»ƒæ•°æ®"""
        data = []
        
        for i in range(num_periods):
            # ç”Ÿæˆéšæœºå·ç 
            number = np.random.randint(0, 1000)
            digits = [number // 100, (number // 10) % 10, number % 10]
            
            # è®¡ç®—ç‰¹å¾
            features = self.calculate_features(i, digits)
            data.append(features)
        
        return pd.DataFrame(data, columns=self.feature_names)
    
    def calculate_features(self, period, digits):
        """è®¡ç®—ç‰¹å¾å€¼"""
        hundreds, tens, ones = digits
        
        # åŸºç¡€ç‰¹å¾
        sum_value = sum(digits)
        span_value = max(digits) - min(digits)
        odd_count = sum(1 for d in digits if d % 2 == 1)
        even_count = 3 - odd_count
        big_count = sum(1 for d in digits if d >= 5)
        small_count = 3 - big_count
        
        # è¿ç»­æ•°å­—ç‰¹å¾
        consecutive_count = 0
        if abs(hundreds - tens) == 1 or abs(tens - ones) == 1:
            consecutive_count = 1
        
        # æ—¶é—´ç‰¹å¾
        day_of_week = period % 7
        month = (period // 30) % 12 + 1
        
        return [
            period, day_of_week, month, hundreds, tens, ones,
            sum_value, span_value, odd_count, even_count,
            big_count, small_count, consecutive_count
        ]
    
    def train_models(self, data):
        """è®­ç»ƒå¤šä¸ªæ¨¡å‹"""
        # ä¸ºæ¯ä¸ªä½ç½®è®­ç»ƒå•ç‹¬çš„æ¨¡å‹
        positions = ['hundreds', 'tens', 'ones']
        
        for pos in positions:
            # å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡
            X = data.drop(['hundreds', 'tens', 'ones'], axis=1)
            y = data[pos]
            
            # æ ‡å‡†åŒ–ç‰¹å¾
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X)
            
            # è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹
            model = RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                n_jobs=-1
            )
            model.fit(X_scaled, y)
            
            # ä¿å­˜æ¨¡å‹å’Œæ ‡å‡†åŒ–å™¨
            self.models[pos] = model
            self.scalers[pos] = scaler
    
    def predict_next_number(self, last_period_data):
        """é¢„æµ‹ä¸‹ä¸€ä¸ªå·ç """
        predictions = {}
        
        for pos in ['hundreds', 'tens', 'ones']:
            # å‡†å¤‡ç‰¹å¾
            X = last_period_data.drop(['hundreds', 'tens', 'ones'], axis=1)
            X_scaled = self.scalers[pos].transform(X)
            
            # é¢„æµ‹
            pred = self.models[pos].predict(X_scaled)[0]
            
            # å°†é¢„æµ‹ç»“æœé™åˆ¶åœ¨0-9èŒƒå›´å†…
            predictions[pos] = max(0, min(9, round(pred)))
        
        return predictions
    
    def get_feature_importance(self):
        """è·å–ç‰¹å¾é‡è¦æ€§"""
        importance_data = {}
        
        for pos, model in self.models.items():
            importance_data[pos] = dict(zip(
                [f for f in self.feature_names if f not in ['hundreds', 'tens', 'ones']],
                model.feature_importances_
            ))
        
        return importance_data

def main():
    """ä¸»å‡½æ•°æ¼”ç¤º"""
    print("ğŸ² ç¦å½©3D AIé¢„æµ‹æ¨¡å‹æ¼”ç¤º")
    print("=" * 50)
    
    # åˆ›å»ºé¢„æµ‹å™¨
    predictor = LotteryAIPredictor()
    
    # ç”Ÿæˆè®­ç»ƒæ•°æ®
    print("ğŸ“Š ç”Ÿæˆè®­ç»ƒæ•°æ®...")
    training_data = predictor.generate_training_data(1000)
    print(f"è®­ç»ƒæ•°æ®å½¢çŠ¶: {training_data.shape}")
    
    # è®­ç»ƒæ¨¡å‹
    print("ğŸ¤– è®­ç»ƒAIæ¨¡å‹...")
    predictor.train_models(training_data)
    print("æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    
    # æ˜¾ç¤ºç‰¹å¾é‡è¦æ€§
    print("\nğŸ“ˆ ç‰¹å¾é‡è¦æ€§åˆ†æ:")
    importance = predictor.get_feature_importance()
    
    for pos, features in importance.items():
        print(f"\n{pos.upper()}ä½ç‰¹å¾é‡è¦æ€§:")
        sorted_features = sorted(features.items(), key=lambda x: x[1], reverse=True)
        for feature, score in sorted_features[:5]:
            print(f"  {feature}: {score:.4f}")
    
    # è¿›è¡Œé¢„æµ‹
    print("\nğŸ”® è¿›è¡Œé¢„æµ‹...")
    last_data = training_data.iloc[-1:].copy()
    prediction = predictor.predict_next_number(last_data)
    
    predicted_number = f"{prediction['hundreds']}{prediction['tens']}{prediction['ones']}"
    print(f"AIé¢„æµ‹å·ç : {predicted_number}")
    
    # ç”Ÿæˆå¤šä¸ªé¢„æµ‹
    print("\nğŸ¯ ç”Ÿæˆå¤šä¸ªé¢„æµ‹ç»“æœ:")
    for i in range(5):
        # æ¨¡æ‹Ÿä¸åŒçš„å†å²æ•°æ®
        random_data = training_data.sample(1).copy()
        pred = predictor.predict_next_number(random_data)
        number = f"{pred['hundreds']}{pred['tens']}{pred['ones']}"
        print(f"  é¢„æµ‹ {i+1}: {number}")
    
    print("\nâš ï¸  é‡è¦æé†’:")
    print("1. æ­¤æ¨¡å‹ä»…ç”¨äºå­¦ä¹ å’Œç ”ç©¶ç›®çš„")
    print("2. å½©ç¥¨å…·æœ‰éšæœºæ€§ï¼Œä»»ä½•é¢„æµ‹éƒ½æ— æ³•ä¿è¯å‡†ç¡®æ€§")
    print("3. è¯·ç†æ€§è´­å½©ï¼Œé‡åŠ›è€Œè¡Œ")
    print("4. æœ¬æ¨¡å‹ä¸æ„æˆæŠ•èµ„å»ºè®®")

if __name__ == "__main__":
    main()
